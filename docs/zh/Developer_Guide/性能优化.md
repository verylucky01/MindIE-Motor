*服务性能调优专项指南，包含并发配置、批处理策略、资源限制、后端优化等高级主题*

# 性能调优

## 性能调优流程

通过参数调优，使吞吐率（TPS）达到时延约束条件下的最大值。

### 性能调优环境变量配置

| 参数名称                 | 默认值 | 说明                                                         | 推荐值                                                       |
| ------------------------ | ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| MIES_USE_MB_SWAPPER      | 0      | 开启高性能swap（不设置时默认关闭）；Atlas推理系列产品（Atlas 300I DUO推理卡）上需要关闭该参数 `<br>`0:关闭 `<br>`1:开启 | MaxPreemptCount>0时，此时简易开启高性能Swap。`` export MIES_USE_MB_SWAPPER=1 |
| MIES_RECOMPUTE_THRESHOLD | 0.5    | 表示当前可下发的请求block数占总block数的比例(也就是block资源利用率)。`<br>`以0.5为例，当前可下发的请求资源利用率小于0.5时，就会触发重计算，释放少量请求的block，来保证其他请求资源使用。阈值访问只能是[0,1)，值越大越容易触发重计算。0表示所有请求都无法下发。 | 取值建议在0.5上下浮动调整。`<br>`export MIES_RECOMPUTE_THRESHHOLD=0.5 |

### 最优性能参数配置

| 配置类型 | 配置项                    | 配置介绍                                                     | 推荐配置                                                     |
| -------- | ------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 调度配置 | maxPrefillbatchSize       | Prefill阶段一个batch中包含请求个数的上限                     | 小于等于maxBatchsize的值，建议设置为：maxBatchSize/2，若显存溢出可适当调小。`<br>`该参数主要是在明确需要限制prefill阶段一个batch可以组的最大请求数量的场景下使用，否则可以设置为0（此时引擎将默认取maxBatchSize值）或与maxBatchSize值相同`<br>`必填，默认值：50 |
|          | maxPrefillTokens          | Prefill阶段一个batch中包含input token总数的上限              | maxPrefillBatchSize * 数据集token id 平均输入长度。`<br>`不建议设置过大，若显存溢出可适当调小。 |
|          | maxBatchSize              | Decode阶段一次推理包含请求的最大个数                         | 1.根据maxBatchSize参数中的公式计算出最大值`<br>`2.如果需要限制Decode时延，可适当调整maxBatchSize大小，一般情况maxBatchSize越小，吞吐量会降低，Decode时延越小 |
|          | supportSelectBatch        | false：关闭，表示有限执行Prefill`<br>`true:开启，优化stage执行优先级；根据prefillTimeMsperReq和decodeMsPerReq被优先执行的概率越低，也就是prefill会等到多轮decode后再执行 | 吞吐量有限时。建议设置为：true。`<br>`首token时延优先时，建议设置为：false |
|          | prefillTimeMsPerReq       | 平均每个请求prefill时间`<br>`"supportSelectbatch"设置为“true”时生效 | 建议值：600，单位为ms；若需要降低首token时延可适当调小。`<br>`计算与decodeTimeMsPerReq的比值，即prefillTimeMsperReq/decodeTimeMsPerReq，该比值越大，调度时优先做Decode，会降低Decode时延，提高首token时延。 |
|          | decodeTimeMsPerReq        | 平均每个请求decode时间``"supportSelectbatch"设置为“true”时生效                                                                                                                                                                                                      | 建议值：50，单位为ms。`<br>`建议仅调整prefillTimeMsPerReq值，该值固定为50ms。 |                                                              |
|          | maxQueueDelayMicroseconds | 请求在队列中的最大等待时间                                   | 在队列中的请求数量达到最大maxBatchSize、maxPrefillbatchSize或maxPrefillTokens前，请求在队列中的最大等待时间，单位：us。`<br>`只要等待时间达到该值，即使请求数量未达到最大maxBatchSize、maxPrefillBatchSize或maxPrefillTokens，也要进行才一次推理。`<br>`必填，默认值：5000 |
|          | maxPreemptCount           | 每一批次最大可抢占请求的上限，即限制一轮调度最多抢占请求的数量，最大上限为maxBatchSize，取值大于0则表示开启可抢占功能 | [0，maxBatchSize]，当取值大于0时，cpuMemsize取值不可为0。`<br>`建议值：0（关闭）。`<br>`当环境变量MIES_USE_MS_SWAPPER为1时该参数生效 |
| 模型配置 | worldSize                 | 节点可以使用的NPU卡数                                        | 根据用户实际情况启用NPU卡数量。                              |
|          | npuDeviceIds              | 推理使用的一组NPU卡号                                        | [0,1,2,...,worldSize-1]                                      |
|          | npuMemsize                | 单个NPU中可以用来申请KV Cache的size上限，单位GB              | npuMemSize=(单卡总空闲-权重/NPU卡数-后处理占用)*系数，其中系数去0.8.`<br>`通常情况下，大模型推理主要是显存bound，因此该值配置的越大，KV Cache可用的显存越多，BatchSize就越大，吞吐量将会更优。（说明：在一些小模型场景下，显存充足，主要是计算bound，调大显存效果并不明显） |
|          | cpuMemsize                | 单个CPU中可以用来申请KV Cache的size上限，单位GB`<br>`开启Swap时生效，如何开启清参考环境变量优化性能中的MIES_USE_MB_SWAPPER环境变量 | 上限根据显存和用户需求来决定。只有当maxPreemptCount为0时，才可以取值为0。`<br>`建议值：5 |
|          | cacheBlockSize            | 表示一个block块的大小                                        | 根据请求平均输入输出大小确定，一般默认为128，如果平均输入较小可以适当调小。 |
| 其他配置 | LogLevel                  | 设置日志级别。`<br>`"Verbose"：打印Verbose、Info、Warning和ERROR级别的日志`<br>`"Info"：打印Info、warning和ERROR级别的日志`<br>`"Warn"：打印Warning和ERROR级别的日志。`<br>`"ERROR"：打印ERROR级别的日志`<br>`"Debug"：打印Verbose、Info、Warning和ERROR级别的日志 | 建议值：“ERROR”，打印ERROR级别的日志                         |

### 操作步骤

以下操作步骤以LLaMA3-8B双卡，数据类型bfloat16为例，进行最优性能的配置，环境信息举例如下：

本机配置8张显存大小为32G的卡，每张卡空闲状态下已经占用3G，以占用2卡进行操作。

**步骤1** （可选）性能调优前需要需要开启CPU高性能模式和透明大页、jemalloc优化来提升性能，这三种方式相互独立，可以开启其中一个或多个。

- 在裸机中执行以下命令开启CPU高性能模式和透明大页，开启后可提升性能

  ```
  cpupower -c all frequency-set -g performance
  ```
- 开启透明大页，多次时延的吞吐量结果会更稳定

  ```
  echo always > /sys/kernel/mm/transparent_hugepage/enabled
  ```

  说明：

  服务号进程可能与模型执行进程抢占CPU资源，导致性能时延波动；可以在启动服务时将服务化进程手动绑至CPU奇数核，以减少性能波动，具体方法如下所示。

  1. 使用lscpu命令查看系统CPU配置情况

     ```
     lscpu
     ```

     cpu相关配置回显信息如下：

     ```
     NUMA：
     	NUMA node(s)：            8
     	NUMA node0 CPU(s)：       0-23
     	NUMA node1 CPU(s)：       24-47
     	NUMA node2 CPU(s)：       48-71
     	NUMA node3 CPU(s)：       72-95
     	NUMA node4 CPU(s)：       96-119
     	NUMA node5 CPU(s)：       120-143
     	NUMA node6 CPU(s)：       144-167
     	NUMA node7 CPU(s)：       168-191
     ```
  2. 使用使用taskset -c命令将服务化进程绑核至CPU奇数核并启动

     ```
     taskset -c $cpus ./bin/mindieservice_daemon
     ```

     $cpus：为cpu配置回显信息中node1、node3、node5或者node7的值
- jemalloc优化需要用户自行编译jemalloc动态链接库，并在脚步里引入编译好的动态链接库，具体步骤如下

  1. 单机链接下载jemalloc源码，并参考INSTALL.md文件编译按照
  2. 拉起服务前，将jemalloc动态链接引入环境，执行如下命令。

     ```
     export LD_PRELOAD = " {$path_to_lib}/libjemalloc.so:$LD_PRELOAD"
     ```

     其中path_to_lib为libjemalloc.so所在路径。

**步骤2**  计算模型配置参数，请参考表 最优性能参数配置中的“npuMemSize”参数计算出"npuMemSize"的值并根据计算结果调整配置中的该值，计算过程如下所示。

1. 计算模型的权重大小，进入模型权重文件所在目录，使用“du -h”命令查看模型的权重大小。如图 查看权重大小所示，LlaMA3-8B模型权重大小为15G。

   查看权重大小：

   ```
   cd /model_weight_path/weights/LLaMA3-8B
   du -h
   ```
2. 计算“npuMemsize”的值，计算公式为：Floor[(单卡显存-空闲占用-权重/NPU卡数)* 系数]，系数取值为0.8。

   npuMemSize = Floor[( 32 - 3 -15 /2 )] * 0.8 = 17G。

   说明：“Floor”表示向下取整。

   根据计算结果，配置实例如下所示：

   ```
   "ModelDeployConfig":
   	{
   		"maxSeqLen" : 2560,
   		"maxInputTokenLen" : 2048,
   		"truncation" : false,
   		"ModelConfig" : [
   			{
   				"modelInstanceType" : "Standard",
   				"modelname" : "LLaMa3-8B",
   				"modelWeightPath" : "/home/data/acltransformer_testdata/weights/LLaMa3-8B",
   				"worldSize" : 2,
   				"cpuMemSize" : 17,
   				"BackendType" : "atb"
   			}
   		]
   	},
   ```

   说明：

   - “worldSize”、"npuDeviceIds"、“CacheBlockSize”、“npuMemsize”和“cpuMemsize”参数请参见表最优性能参数配置取建议值
   - 其他参数取值请取默认值

**步骤3** 计算调度配置参数，请参考“maxBatchSize”参数计算出“maxBatchSize”的值并根据计算结果调整配置中的该值，计算过程如下所示。

根据计算公式：maxBatchSize = Total Block Num /Block Num，需要计算出“Total Block Num”和Block Num的值。

1. 计算“Total Block Num”的值。

   - 方式一（实测获取）：

     - “Total Block Num”的值可以通过跑一次性能后再Python日志中的“numBlockNum”获取，Python日志路径为：/usr/local/Ascend/mindie/latest/mindie-llm/logs/pythonlog.log

       说明：当使用多卡跑性能时，Python日志会根据使用的卡数打印多个“npuBlockNum”，此时获取最小值即可。
     - “Total Block Num”的值也可以直接从info级打印日志k_caches[0].shape=torch.Size([npuBlockNum,-,-,-])中torch.Size的第一个值获取。
   - 方式二（公式计算）：

     Total Block Num = Floor[NPU显存/(模型网络层数*cacheBlockSize*模型注意力头数 * 注意力头大小 * Cache)类型字节数 * Cache数]，公式中各参数的取值信息如表Total Block Num公式中的参数值所示。

     表3 Total Block Num公式中的参数值

     | 参数            | 取值                                                         |
     | --------------- | ------------------------------------------------------------ |
     | NPU显存         | 2中“npuMemSize”的值：17。                                    |
     | 模型网络层数    | 模型网络层数是权重文件config.json中num_hidden_layers参数的值，取值为：32. |
     | cacheBlockSize  | 默认值：128。该参数的值与cacheBlockSize参数的值保持一致      |
     | 模型注意力头数  | 模型注意力头数是模型权重文件config.json中num_attention_heads参数的值 |
     | 注意力头数大小  | “模型注意力头数*注意力大小”的值为模型权重文件config.json中hidden_size参数的值（取值为:4096），即注意力头大小可以根据模型注意力头数计算获取。`<br>`说明`<br>`对于GQA模型（分组参训注意力类模型，例如LLaMa3-8B），“模型注意力头数”的值需要使用模型权重文件config.json中num_key_value_heads参数的值（取值为：8），即对LLaMa3-8B模型，其“注意力头大小”的值应该为4096/8=512。 |
     | Cache类型字节数 | 由模型config.json文件中的torch_dtype决定，一般为float16类型，取值为：2. |
     | Cache数         | Key+Value的值，各自代表1个Cache数。默认值：2.                |

     将以上参数代入公式，得到Total Block Num = Floor[17 * 1024 * 1024 * 1024 / (32 * 128 * 8 * 512 / 2 * 2 * 2)] = 544。

     注：以上算式中512/2是由于LLaMa3-8B双卡，所以注意力头数需均匀分在2张卡上。
2. 计算每个请求所需“Block Num”的值，公式中各参数的取值信息如表 BlockNum公式中的参数值所示。

   根据计算公式：

   - 所需最小Block Num = Ceil(输入Token数/cacheBlockSize)
   - 所需最大Block Num = Ceil(输入Token数/cacheBlockSize)+Ceil(最大输出Token数/cacheBlockSize)
   - 所需平均Block Num = Ceil(输入Token数/cacheBlockSize)+Ceil(平均输出Token数/cacheBlockSize)

   表4 Block Num公式中的参数值

   | 参数            | 取值                                                         |
   | --------------- | ------------------------------------------------------------ |
   | 输入Token数     | 从Benchmark输出的InputTokens参数的平均值获取，取值示例：186。 |
   | 最大输出Token数 | 从config.json文件中的maxiterTimes参数获取，实例取值：512。   |
   | 平均输出Token数 | 实际运行测试数据集后统计GeneratedTokens参数平均输出长度，实例取值：346. |
   | cacheBlockSize  | 默认值：128。该参数的值与最优性能参数配置中cacheBlockSize的值保持一致。 |

   将以上参数值代入公式：


   - 所需最小Block Num = Ceil(186/128) = 2
   - 所需最大Block Num = Ceil(186/128)  + Ceil(512/128) = 6
   - 所需平均Block Num = Ceil(186/128)  + Ceil(346/128) = 5
3. 计算maxBatchSize的取值范围

   根据3.a和3.b计算出的“Total Block Num”和“Block Num”值，然后使用公式maxBatchSize=Floor[Total Block Num/Block Num]计算“maxBatchSize”的取值范围。

   - 最小maxBatchSize = Floor[Total Block Num/所需最大Block Num] = 90
   - 最大maxBatchSize = Floor[Total Block Num/所需最小Block Num] = 272
   - 平均maxBatchSize = Floor[Total Block Num/所需平均Block Num] = 108

     由以上公式得到“maxBatchSize”的取值范围为[90,272]，设置初始值为200，然后根据吞吐量或者时延要求进行调整，具体场景请参数最佳实践。

**步骤4**  计算“maxPrefillBatchSize”和“maxPrefillTokens”的值。

- “maxPrefillBatchSize”的计算方式请参见表 最优性能参数配置中的“maxPrefillBatchSize”参数，建议设置为：“maxPrefillTokens”值的一半。

  maxPrefillBatchSize = Floor[maxBatchSize/2] = 200/2 = 100
- “maxPrefillTokens”的值一般不超过8192，其计算方式请参见表 最优性能参数配置中“maxPrefilTokens”参数。

  maxPrefillTokens = maxPrefillBatchSize * 数据集token id平均输入长度 = 100 * 186 = 18600

  根据公式计算出的值大于8192，所以“maxPrefillBatchSize”的取值为8192。

  说明：

  - “maxPrefillBatchSize”和“maxPrefillTokens”的值一般根据“maxBatchSize”的值进行调整，其值不建议过大。
  - “maxPrefillTokens”一般不用超过8192，若显存溢出可进一步适当调小“maxPrefillBatchSize”和“maxPrefillTokens”的值。

**步骤5**  通过配置“maxPreemptCount”和“cpuMemsize”参数确认Swap抢占，请参见表最优性能参数配置其建议值

    说明：如果是显存首先场景，可开启“maxPreemptCount”（即设置为1或2），“cpuMemsize”可从5调整至40.

**步骤6**  通过配置“supportSelectBatch”、“prefillTimeMsPerReq”和“decodeTimeMsPerReq”参数确认Prefill/Decode切换调度策略。

- 当严格要求首Token时延时：

    “supportSelectBatch”设置为“false”。

- 当严格要求吞吐量时（首token时延要求适中）：

  “supportSelectBatch”设置为“True”

  “prefillTimeMsPerReq”和“decodeTimeMsPerReq”按照模型实际平均值token时延和Decode时延设置。也可参见表 最优性能参数配置使用推荐配置，然后根据下列场景进行调优。

  - 场景一：若希望降低首token时延：

    可调小“prefiilTimeMsPerReq”，并调小“decodeTimeMsPerReq”，使Decode优先执行。
  - 场景二：

    可适当调大“prefiillTimeMsPerReq”，并调小“decodeTimeMsPerReq”，使Prefill有限执行。

**步骤7**  实际运行时，若测试场景是显存bound，可进一步调整“npuMemSize”的值。

在调试过程中，重开一个窗口使用一下命令查看占卡情况，如果剩余空间还很大，可以调大npuMemSize的值，重复3~6后再次调试。

```
watch npu-smi info
```

- 当npuMemSize的值不够大时，可以继续调大空闲值，npuMemSize值不够大
- 当npuMemSize的值过大时，则会报“Npu out of memory”错误
- 根据“Npu out of memory”报错信息，将npuMemSize的值调小（比如在原来的值上减2，避免卡死），则可以达到最优npuMemSize的值。大概是占据95%卡的状态

## 最佳实践

### 不考虑时延的极限吞吐

不考虑时延的极限吞吐的调试方式如下所示。

- 服务端：
  - “maxBatchSize”尽量调大到显存限制，一般情况下“maxBatchSize”值越大，则吞吐越大；若“maxBatchSize”增大时吞吐量不增反降，则停止调整。
  - 设置supportSelectBatch为true，“prefillTimeMsPerReq”和“decodeTimeMsPerReq”按照模型实际平均首token时延和Decode时延进行设置。
- 客户端：
  - 按并发数发送请求：客户端Concurrency的值通常配置为maxBatchSize的值减1。
  - 按频率发送请求：则Concurrency可设置为1000，请求发送频率根据实际业务场景或按模型实际QPS设置。

操作步骤

**步骤1** （可选）性能调优前需要开启CPU高性能模式和透明大页、jemalloc优化来提升性能，这三种方式相互独立，可以开启其中一个或多个。

- 在裸机中执行以下命令开启CPU高性能模式和透明大页，开启后可提升性能。

  - 开启CPU高性能模式，在相同时延约束下，TPS会有约3%的提升。

    ```
    cpupower -c all frequency-set -g performance
    ```

  - 开启透明大页，多次实验的吞吐率结果会更稳定。

    ```
    echo always > /sys/kernel/mm/transparent_hugepage/enabled
    ```

    <div style="background:#f0f9ff;border-left:4px solid #2196f3;padding:14px;margin:16px 0;border-radius:6px;">
    <strong>💡 说明</strong>
    <ul style="margin:8px 0;padding-left:20px;">
    服务化进程可能与模型执行进程抢占CPU资源，导致性能时延波动；可以在启动服务时将服务化进程手动绑核至CPU奇数核，以减少CPU抢占影响，降低性能波动，具体方法如下所示。
        <ol>
        <li>使用lscpu命令查看系统CPU配置情况。</li>
        <code>lscpu</code><br>
         CPU相关配置回显信息如下所示：<br>
         <code>NUMA:<br>
             NUMA node(s):         8<br>
             NUMA node0 CPU(s):    0-23<br>
             NUMA node1 CPU(s):    24-47<br>
             NUMA node2 CPU(s):    48-71<br>
             NUMA node3 CPU(s):    72-95<br>
             NUMA node4 CPU(s):    96-119<br>
             NUMA node5 CPU(s):    120-143<br>
             NUMA node6 CPU(s):    144-167<br>
             NUMA node7 CPU(s):    168-191<br>
            </code>
        <li>使用taskset -c命令将服务化进程绑核至CPU奇数核并启动。</li>
        <code>taskset -c $cpus ./bin/mindieservice_daemon</code><br>
        $cpus：为CPU配置回显信息中node1、node3、node5或node7的值。
    </ol>
    </ul></div>

- jemalloc优化需要用户自行编译jemalloc动态链接库，并在脚本里引入编译好的动态链接库，具体步骤如下。

  1. 单机链接下载jemalloc源码，并参考INSTALL.md文件编译安装。

  2. 拉起服务前，将jemalloc动态链接库引入环境，执行如下命令。

     ```
     export LD_PRELOAD="{$path_to_lib}/libjemalloc.so:$LD_PRELOAD"
     ```

     其中path_to_lib为libjemalloc.so所在路径。

**步骤2** 使用以下命令启动服务，以当前所在Ascend-mindie-service_{version}_linux-{arch}目录为例。

```
./bin/mindieservice_daemon
```

回显如下则说明启动成功。

```
Daemon start success!
```

服务启动后，可通过info级打印日志k_caches[0].shape=torch.Size([npuBlockNum, x, x, x])中torch.Size的第一个值获取npuBlockNum的值，如图 启动成功所示，与性能调优流程3.a中计算出来的值一致。

**步骤3** 根据性能调优流程3.c计算出“maxBatchSize”的取值范围为[90，272]，设置初始值为200；“maxPrefillBatchSize”参数的值设置为“maxBatchSize”值的一半，取值为100。

**步骤4**  配置完成后，用户可使用HTTPS客户端（Linux curl命令，Postman工具等）发送HTTPS请求，此处以Linux curl命令为例进行说明。

重开一个窗口，使用MindIE Benchmark工具发送请求，获取当前的吞吐量（OutputGenerateSpeed），此时吞吐量为2845.3 token/s。也可以使用AISBench工具进行性能测试。

```
benchmark \
--DatasetPath "/{数据集路径}/GSM8K" \
--DatasetType "gsm8k" \
--ModelName LLaMa3-8B \
--ModelPath "/{模型路径}/LLaMa3-8B" \
--TestType client \
--Http https://{ipAddress}:{port} \
--ManagementHttp https://{managementIpAddress}:{managementPort}  \
--Concurrency 1000 \
--TaskKind stream \
--Tokenizer True \
--MaxOutputLen 512
```

**步骤5**  以“100”为单位且取整向上调试“maxBatchSize”的值，所以设置“maxBatchSize”的值为300，“maxPrefillBatchSize”参数的值设置为150。然后执行4，继续观察不考虑时延的极限吞吐，此时吞吐量为2980.3 token/s。

**步骤6**  由于“maxBatchSize”的值为300的吞吐量优于“maxBatchSize”的值为200，所以继续设置“maxBatchSize”的值为400，“maxPrefillBatchSize”参数的值为200。然后执行4，观察其吞吐量，此时吞吐量为2520.6 token/s。

当“maxBatchSize”的值为400时，此时的吞吐量明显下降，停止调高“maxBatchSize”的值。

综上所述，当“maxBatchSize”的值在300左右时，可达到极限吞吐。如需获取达到极限吞吐时更精准的“maxBatchSize”值，请根据以上操作步骤继续调试。

### 限制非首token时延的极限吞吐

以Decode平均时延限制50ms以内为目标，限制非首token时延的极限吞吐的调试方式如下所示。

- 服务端：
  - “maxBatchSize”调小到卡对应的时延，一般情况下“maxBatchSize”越小，则Decode时延越小。
  - 设置supportSelectBatch为true，“prefillTimeMsPerReq”和“decodeTimeMsPerReq”按照模型实际平均首token时延和Decode时延进行设置。
- 客户端：
  - 按并发数发送请求：客户端Concurrency通常配置为maxBatchSize-1。
  - 按频率发送请求：则Concurrency可设置为1000，请求发送频率根据实际业务场景或按模型实际QPS设置。

**操作步骤**

**步骤1**（可选）性能调优前需要开启CPU高性能模式和透明大页、jemalloc优化来提升性能，这三种方式相互独立，可以开启其中一个或多个。

- 在裸机中执行以下命令开启CPU高性能模式和透明大页，开启后可提升性能。

  - 开启CPU高性能模式，在相同时延约束下，TPS会有约3%的提升。

    ```
    cpupower -c all frequency-set -g performance
    ```

  - 开启透明大页，多次实验的吞吐率结果会更稳定。

    ```
    echo always > /sys/kernel/mm/transparent_hugepage/enabled
    ```

  <div style="background:#f0f9ff;border-left:4px solid #2196f3;padding:14px;margin:16px 0;border-radius:6px;">
  <strong>💡 说明</strong>
  <ul style="margin:8px 0;padding-left:20px;">
  服务化进程可能与模型执行进程抢占CPU资源，导致性能时延波动；可以在启动服务时将服务化进程手动绑核至CPU奇数核，以减少CPU抢占影响，降低性能波动，具体方法如下所示。
      <ol>
      <li>使用lscpu命令查看系统CPU配置情况。</li>
      <code>lscpu</code><br>
       CPU相关配置回显信息如下所示：<br>
       <code>NUMA:<br>
           NUMA node(s):         8<br>
           NUMA node0 CPU(s):    0-23<br>
           NUMA node1 CPU(s):    24-47<br>
           NUMA node2 CPU(s):    48-71<br>
           NUMA node3 CPU(s):    72-95<br>
           NUMA node4 CPU(s):    96-119<br>
           NUMA node5 CPU(s):    120-143<br>
           NUMA node6 CPU(s):    144-167<br>
           NUMA node7 CPU(s):    168-191<br>
          </code>
      <li>使用taskset -c命令将服务化进程绑核至CPU奇数核并启动。</li>
      <code>taskset -c $cpus ./bin/mindieservice_daemon</code><br>
      $cpus：为CPU配置回显信息中node1、node3、node5或node7的值。
  </ol>
  </ul></div>

- jemalloc优化需要用户自行编译jemalloc动态链接库，并在脚本里引入编译好的动态链接库，具体步骤如下。

  1. 单机链接下载jemalloc源码，并参考INSTALL.md文件编译安装。

  2. 拉起服务前，将jemalloc动态链接库引入环境，执行如下命令。

     ```
     export LD_PRELOAD="{$path_to_lib}/libjemalloc.so:$LD_PRELOAD"
     ```

     其中path_to_lib为libjemalloc.so所在路径。

**步骤2** 使用以下命令启动服务，以当前所在Ascend-mindie-service_{version}_linux-{arch}目录为例。

```
./bin/mindieservice_daemon
```

回显如下则说明启动成功。

```
Daemon start success!
```

服务启动后，可通过info级打印日志k_caches[0].shape=torch.Size([npuBlockNum, x, x, x])中torch.Size的第一个值获取npuBlockNum的值，如图 启动成功所示，与7.1-3.a中计算出来的值一致。

**步骤3** 根据性能调优流程3.c计算出“maxBatchSize”的取值范围为[90，272]，设置初始值为200；“maxPrefillBatchSize”参数的值设置为“maxBatchSize”值的一半，取值为100。

**步骤4** 配置完成后，用户可使用HTTPS客户端（Linux curl命令，Postman工具等）发送HTTPS请求，此处以Linux curl命令为例进行说明。

重开一个窗口，使用MindIE Benchmark工具发送请求，获取当前Decode Time的平均值，此时Decode平均时延为60.1889ms。也可以使用AISBench工具进行性能测试。

```
benchmark \
--DatasetPath "/{数据集路径}/GSM8K" \
--DatasetType "gsm8k" \
--ModelName LLaMa3-8B \
--ModelPath "/{模型路径}/LLaMa3-8B" \
--TestType client \
--Http https://{ipAddress}:{port} \
--ManagementHttp https://{managementIpAddress}:{managementPort}  \
--Concurrency 1000 \
--TaskKind stream \
--Tokenizer True \
--MaxOutputLen 512
```

以上结果超过了Decode平均时延为50ms的限制，所以需要调小“maxBatchSize”的值继续调试。

**步骤5** 设置“maxBatchSize”的值为100，“maxPrefillBatchSize”参数的值设置为50。然后执行4，继续观察Decode平均时延，此时decode平均时延为46.9689ms。

以上结果可以看到Decode平均时延满足50ms以内的限制，但是还未接近50ms，所以需要调大“maxBatchSize”的值继续进行调试。

**步骤6** 设置“maxBatchSize”的值为150，“maxPrefillBatchSize”参数的值设置为75。然后执行4，继续观察Decode平均时延，此时decode平均时延为49.846ms。

以上结果可以看到Decode平均时延已经很接近50ms，此时几乎已达到限制Decode时延下的最大吞吐量。如需获取Decode平均时延更接近50ms时的“maxBatchSize”值，请根据以上操作步骤继续调试。

### 首token时延限制严格，非首token时延也有限制

以首token平均时延限制在8000ms以内、Decode平均时延限制50ms以内为目标，首token时延限制严格，且非首token时延也有限制的调试方式如下所示。

- 服务端：
  - “maxBatchSize”调小到卡对应的时延，一般情况下“maxBatchSize”越小，则Decode时延越小。
  - 设置supportSelectBatch为false。
- 客户端：
  - 按并发数发送请求：客户端Concurrency通常配置为maxBatchSize-1。
  - 按频率发送请求：则Concurrency可设置为1000，请求发送频率根据实际业务场景或按模型实际QPS设置。

**步骤1**（可选）性能调优前需要开启CPU高性能模式和透明大页、jemalloc优化来提升性能，这三种方式相互独立，可以开启其中一个或多个。

- 在裸机中执行以下命令开启CPU高性能模式和透明大页，开启后可提升性能。

  - 开启CPU高性能模式，在相同时延约束下，TPS会有约3%的提升。

    ```
    cpupower -c all frequency-set -g performance
    ```

    

  - 开启透明大页，多次实验的吞吐率结果会更稳定。

    ```
    echo always > /sys/kernel/mm/transparent_hugepage/enabled
    ```

  <div style="background:#f0f9ff;border-left:4px solid #2196f3;padding:14px;margin:16px 0;border-radius:6px;">
  <strong>💡 说明</strong>
  <ul style="margin:8px 0;padding-left:20px;">
  服务化进程可能与模型执行进程抢占CPU资源，导致性能时延波动；可以在启动服务时将服务化进程手动绑核至CPU奇数核，以减少CPU抢占影响，降低性能波动，具体方法如下所示。
      <ol>
      <li>使用lscpu命令查看系统CPU配置情况。</li>
      <code>lscpu</code><br>
       CPU相关配置回显信息如下所示：<br>
       <code>NUMA:<br>
           NUMA node(s):         8<br>
           NUMA node0 CPU(s):    0-23<br>
           NUMA node1 CPU(s):    24-47<br>
           NUMA node2 CPU(s):    48-71<br>
           NUMA node3 CPU(s):    72-95<br>
           NUMA node4 CPU(s):    96-119<br>
           NUMA node5 CPU(s):    120-143<br>
           NUMA node6 CPU(s):    144-167<br>
           NUMA node7 CPU(s):    168-191<br>
          </code>
      <li>使用taskset -c命令将服务化进程绑核至CPU奇数核并启动。</li>
      <code>taskset -c $cpus ./bin/mindieservice_daemon</code><br>
      $cpus：为CPU配置回显信息中node1、node3、node5或node7的值。
  </ol>
  </ul></div>

- jemalloc优化需要用户自行编译jemalloc动态链接库，并在脚本里引入编译好的动态链接库，具体步骤如下。

  1. 单机链接下载jemalloc源码，并参考INSTALL.md文件编译安装。

  2. 拉起服务前，将jemalloc动态链接库引入环境，执行如下命令。

     ```
     export LD_PRELOAD="{$path_to_lib}/libjemalloc.so:$LD_PRELOAD"
     ```

     其中path_to_lib为libjemalloc.so所在路径。

**步骤2** 使用以下命令启动服务，以当前所在Ascend-mindie-service_{version}_linux-{arch}目录为例。

```
./bin/mindieservice_daemon
```

回显如下则说明启动成功。

```
Daemon start success!
```

服务启动后，可通过info级打印日志k_caches[0].shape=torch.Size([npuBlockNum, x, x, x])中torch.Size的第一个值获取npuBlockNum的值，性能调优流程3.a中计算出来的值一致。

**步骤3** 根据性能调优流程3.c计算出“maxBatchSize”的取值范围为[90，272]，设置初始值为200；“maxPrefillBatchSize”参数的值设置为“maxBatchSize”值的一半，取值为100。

需要将“supportSelectBatch”参数设置为false，以获取更低的首token时延。

**步骤4** 配置完成后，用户可使用HTTPS客户端（Linux curl命令，Postman工具等）发送HTTPS请求，此处以Linux curl命令为例进行说明。

重开一个窗口，使用MindIE Benchmark工具发送请求，获取当前首token时延 平均值和decode 时延的平均值，此时首token平均时延为21252.0612ms，decode平均时延为73.7486ms。也可以使用AISBench工具进行性能测试，详情请参见3.5-性能测试。

```
benchmark \
--DatasetPath "/{数据集路径}/GSM8K" \
--DatasetType "gsm8k" \
--ModelName LLaMa3-8B \
--ModelPath "/{模型路径}/LLaMa3-8B" \
--TestType client \
--Http https://{ipAddress}:{port} \
--ManagementHttp https://{managementIpAddress}:{managementPort}  \
--Concurrency 1000 \
--TaskKind stream \
--Tokenizer True \
--MaxOutputLen 512
```

以上结果超过了首token平均时延为8000ms和Decode平均时延为50ms的限制，所以需要调小“maxBatchSize”的值继续调试。

**步骤5** 设置“maxBatchSize”的值为150，“maxPrefillBatchSize”参数的值设置为75。然后执行4，继续观察首token平均时延和Decode平均时延，此时首token平均时延为11265.0242ms，Decode平均时延为61.9161ms。

以上结果同样超过了首token平均时延为8000ms和Decode平均时延为50ms的限制，所以需要调小“maxBatchSize”的值继续调试。

**步骤6** 设置“maxBatchSize”的值为100，“maxPrefillBatchSize”参数的值设置为50。然后执行4，继续观察首token平均时延和Decode平均时延，此时首token平均时延为6364.6507ms，Decode平均时延为49.9804ms。

以上结果可以看到首token平均时延和Decode平均时延已经在限制的8000ms和50ms以内，且Decode平均时延已经很接近50ms，此时几乎已达到限制首token时延和Decode时延下的最大吞吐量。如需获取Decode平均时延更接近50ms时的“maxBatchSize”值，请根据以上操作步骤继续调试。